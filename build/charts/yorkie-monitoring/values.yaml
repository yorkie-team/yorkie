# Configuration for monitoring system
monitoring:
  name: &monitoringName yorkie-monitoring
  namespace: &monitoringNamespace monitoring

  # Configured name used for yorkie cluster
  yorkieName: yorkie
  yorkieNamespace: yorkie

  enableEnhancements: &monitoringEnhancementsEnable false

# Configuration for ingress (eg: AWS ALB)
ingress:
  ingressClassName: nginx
  ## Set to alb if you are using AWS, NCP ALB
  # ingressClassName: alb

  # Use same host for yorkie cluster
  hosts:
    enabled: false
    apiHost: &apiHost api.yorkie.dev
    grafanaPath: /grafana

  awsAlb:
    enabled: false
    certArn: arn:aws:acm:ap-northeast-2:123412341234:certificate/1234-1234-1234-1234-1234

  ncpAlb:
    enabled: false
    certNo: 1234

# Configuration for manual prometheus monitoring stack
kube-prometheus-stack:
  # fullnameOverride should be {{monitoring.name}} + "prometheus-stack"
  # TODO(krapie) refactor these values to helper.tpl file
  fullnameOverride: yorkie-monitoring-prometheus-stack
  namespaceOverride: *monitoringNamespace

  # Configuration for alertmanager
  # ref: https://prometheus.io/docs/alerting/alertmanager/
  alertmanager:
    enabled: *monitoringEnhancementsEnable

  # Using default values from
  # ref: https://github.com/grafana/helm-charts/blob/main/charts/grafana/values.yaml
  grafana:
    enabled: true

    # fullnameOverride should be {{monitoring.name}} + "grafana"
    # TODO(krapie) refactor these values to helper.tpl file
    fullnameOverride: yorkie-monitoring-grafana

    defaultDashboardsTimezone: utc
    defaultDashboardsEnabled: false
    adminPassword: yorkie

    service:
      type: NodePort
      
    # For grafana data persistence
    persistence:
      enabled: true
      type: pvc
      # storageClassName: k8s
      accessModes:
      - ReadWriteOnce
      size: 1Gi
      finalizers:
      - kubernetes.io/pvc-protection

    grafana.ini:
      server:
        domain: *apiHost
        root_url: "%(protocol)s://%(domain)s/grafana"
        serve_from_sub_path: true
      
      service:
        type: NodePort
    
    # For grafana dashboards
    dashboardProviders:
      dashboardproviders.yaml:
        apiVersion: 1
        providers:
        - name: 'yorkie'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/yorkie

    # For grafana dashboards
    dashboards:
      yorkie:
        yorkie-dashboard:
          gnetId: 18560
          revision: 2
          datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
        loki-dashboard:
          gnetId: 13186
          revision: 1
          datasource:
          - name: DS_PROMETHEUS
            value: Prometheus
          - name: DS_LOKI
            value: Loki

  # Component scraping the kube api server
  kubeApiServer:
    enabled: *monitoringEnhancementsEnable
  
  # Component scraping the kubelet and kubelet-hosted cAdvisor
  kubelet:
    enabled: *monitoringEnhancementsEnable
  
  # Component scraping the kube controller manager
  kubeControllerManager:
    enabled: *monitoringEnhancementsEnable

  # Component scraping coreDns. Use either this or kubeDns
  coreDns:
    enabled: *monitoringEnhancementsEnable

  # Component scraping kubeDns. Use either this or coreDns
  kubeDns:
    enabled: *monitoringEnhancementsEnable

  # Component scraping etcd
  kubeEtcd:
    enabled: *monitoringEnhancementsEnable
  
  # Component scraping kube scheduler
  kubeScheduler:
    enabled: *monitoringEnhancementsEnable
  
  # Component scraping kube proxy
  kubeProxy:
    enabled: *monitoringEnhancementsEnable

  # Component scraping kube state metrics
  kubeStateMetrics:
    enabled: *monitoringEnhancementsEnable

  # Deploy node exporter as a daemonset to all nodes
  nodeExporter:
    enabled: true

  # Manages Prometheus and Alertmanager components
  prometheusOperator:
    enabled: true

  # Configuration for thanosRuler
  thanosRuler:
    enabled: *monitoringEnhancementsEnable
  
  # Deploy a Prometheus instance
  prometheus:
    enabled: true

    # Use this configuration to allow servicemonitor after helm chart creation
    prometheusSpec:
      serviceMonitorSelectorNilUsesHelmValues: false

      # Prometheus StorageSpec for persistent data
      # ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
      storageSpec:
        # Using PersistentVolumeClaim
        volumeClaimTemplate:
          spec:
            # storageClassName: gluster
            accessModes: ["ReadWriteOnce"]
            resources:
              requests:
                storage: 1Gi
  
  prometheus-node-exporter:
    # fullnameOverride should be {{monitoring.name}} + "prometheus-node-exporter"
    # TODO(krapie) refactor these values to helper.tpl file
    fullnameOverride: yorkie-monitoring-prometheus-node-exporter

  kube-state-metrics:
    # fullnameOverride should be {{monitoring.name}} + "prometheus-state-metrics"
    # TODO(krapie) refactor these values to helper.tpl file
    fullnameOverride: yorkie-monitoring-state-metrics

# Configuration for loki monitoring stack
loki-stack:
  loki:
    isDefault: false
    # fullnameOverride should be {{monitoring.name}} + "loki"
    # TODO(krapie) refactor these values to helper.tpl file    
    fullnameOverride: yorkie-monitoring-loki

    persistence:
      enabled: true
      size: 1Gi

  promtail:
    # fullnameOverride should be {{monitoring.name}} + "promtail"
    # TODO(krapie) refactor these values to helper.tpl file  
    fullnameOverride: yorkie-monitoring-promtail
    
    config:
      clients:
        - url: http://yorkie-monitoring-loki:3100/loki/api/v1/push
